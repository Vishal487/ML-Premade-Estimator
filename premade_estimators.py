# -*- coding: utf-8 -*-
"""Premade Estimators.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1baTa9Yyy0MGuqoMUN48AT1ULEQeWk7dn

This tutorial shows you how to solve the Iris classification problem in TensorFlow using Estimators. An Estimator is TensorFlow's high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training.
"""

import pandas as pd
import tensorflow as tf

"""## The data set
The sample program in this document builds and tests a model that classifies Iris flowers into three different species based on the size of their sepals and petals.

You will train a model using the Iris data set. The Iris data set contains four features and one label. The four features identify the following botanical characteristics of individual Iris flowers:

* sepal length
* sepal width
* petal length
* petal width
"""

CSV_COLUMN_NAMES = ['Sepallength', 'Sepalwidth', 'Petallength', 'Petalwidth', 'Species']
SPECIES = ['Setosa', 'Versicolor', 'Viginica']

train_path = tf.keras.utils.get_file("iris_training.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv")
test_path = tf.keras.utils.get_file("iris_test.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv")

train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)
test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)

train.head()

test.head()

# SEPARATING label

train_y = train.pop('Species')
test_y = test.pop('Species')

train_y.value_counts()

# now see all the features

train.head()

test.head()

"""## Estimators

To write a TensorFlow program based on pre-made Estimators, one must perform the following tasks:

* Create one or more input functions.
* Define the model's feature columns.
* Instantiate an Estimator, specifying the feature columns and various hyperparameters.
* Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data.

### Creating input function

An input function is a function that returns a `tf.data.Dataset` object which outputs the following two-element tuple:

* `features` - A Python dictionary in which:
  * Each key is the name of a feature.
  * Each value is an array containing all of that feature's values.
* `label` - An array containing the values of the `label` for every example.
"""

def input_fn(features, labels=None, training=True, testing=False, batch_size=256):
    """ An input function for training, evaluation and testing """

    # convert the inputs to Dataset.
    if not testing:
        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))
    else:
        dataset = tf.data.Dataset.from_tensor_slices((dict(features)))

    # shuffle and repeat if dataset is for training.
    if training:
        dataset = dataset.shuffle(1000).repeat()

    return dataset.batch(batch_size)

"""### Define feature columns"""

my_feature_columns = []
for key in train.keys():
    my_feature_columns.append(tf.feature_column.numeric_column(key=key))

train.keys()

my_feature_columns

"""## Instantiate an Estimator

The Iris problem is a classic classification problem. Fortunately, TensorFlow provides several pre-made classifier Estimators, including:

* `tf.estimator.DNNClassifier` for deep models that perform multi-class classification.
* `tf.estimator.DNNLinearCombinedClassifier` for wide & deep models.
* `tf.estimator.LinearClassifier` for classifiers based on linear models.

For the Iris problem, `tf.estimator.DNNClassifier` seems like the best choice.
"""

# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each

classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,
                                        hidden_units=[30, 10],
                                        n_classes=3)

"""## Train, Evaluate, and Predict

### Train the model
"""

classifier.train(input_fn=lambda: input_fn(train, train_y, training=True),
                 steps=5000)

"""### Evaluate the trained model"""

eval_result = classifier.evaluate(input_fn= lambda: input_fn(test, test_y, training=False))

print('Evaluation results: ')
print(eval_result)

print('Evaluation results: ')
print(eval_result)

"""### Making Prediction from the trained model
**on the test dataset**
"""

predictions = classifier.predict(input_fn= lambda: input_fn(test, training=False, testing=True))

print(predictions)

for pred_dict, expec in zip(predictions, test_y):
    class_id = pred_dict['class_ids'][0]
    probability = pred_dict['probabilities'][class_id]

    print('Prediction is "{}" ({:.1f}%), expected "{}"'. format(SPECIES[class_id], 100*probability, SPECIES[expec]))

